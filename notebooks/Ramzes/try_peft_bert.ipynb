{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.0-py3-none-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q datasets transformers accelerate loralib sentencepiece gradio fire peft wandb peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import peft\n",
    "from peft import PeftModelForSequenceClassification, LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zip = zipfile.ZipFile('D:\\My_projects\\Grapix\\garpix-solution\\data\\small_boxes.zip', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with data_zip.open(data_zip.filelist[0].filename) as file:\n",
    "    json_file = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.json_normalize(json_file['first_visual']['boxes'])[[\n",
    "    'mass','size.width','size.height', 'size.length'\n",
    "    ]].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = json_file['first_visual']['calculation_info']['density_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_array(json):\n",
    "    \n",
    "    boxes = pd.json_normalize(json['first_visual']['boxes'])[[\n",
    "        'mass', 'size.width', 'size.height', 'size.length'\n",
    "        ]]\n",
    "    target = json['first_visual']['calculation_info']['density_percent']\n",
    "    \n",
    "    return boxes.to_numpy().flatten(), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "targets = []\n",
    "\n",
    "for data_info in data_zip.filelist:\n",
    "    with data_zip.open(data_info.filename) as file:\n",
    "        json_file = json.loads(file.read())\n",
    "        try:\n",
    "            boxes, target = json_to_array(json_file)\n",
    "            if len(boxes) <= 512:\n",
    "                boxes = np.array2string(\n",
    "                    boxes, separator=' ', formatter={'float_kind': lambda x: str(int(x))}\n",
    "                ).replace('[', '').replace(']', '').replace('\\n', '')\n",
    "                arr.append(str(boxes))\n",
    "                targets.append(round(target))\n",
    "            else:\n",
    "                logger.info(f'{data_info.filename} length is more than 512. Skip.')\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            logger.warning(f'\\nError {e} \\n In file {data_info.filename}')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4999, 4999)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr), len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = arr\n",
    "df['labels'] = targets\n",
    "df['labels'] = df['labels'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{77.0: 0,\n",
       " 76.0: 1,\n",
       " 74.0: 2,\n",
       " 56.0: 3,\n",
       " 87.0: 4,\n",
       " 54.0: 5,\n",
       " 100.0: 6,\n",
       " 73.0: 7,\n",
       " 58.0: 8,\n",
       " 62.0: 9,\n",
       " 68.0: 10,\n",
       " 69.0: 11,\n",
       " 71.0: 12,\n",
       " 43.0: 13,\n",
       " 40.0: 14,\n",
       " 82.0: 15,\n",
       " 79.0: 16,\n",
       " 75.0: 17,\n",
       " 81.0: 18,\n",
       " 65.0: 19,\n",
       " 85.0: 20,\n",
       " 67.0: 21,\n",
       " 61.0: 22,\n",
       " 37.0: 23,\n",
       " 84.0: 24,\n",
       " 83.0: 25,\n",
       " 59.0: 26,\n",
       " 45.0: 27,\n",
       " 80.0: 28,\n",
       " 48.0: 29,\n",
       " 89.0: 30,\n",
       " 64.0: 31,\n",
       " 63.0: 32,\n",
       " 51.0: 33,\n",
       " 72.0: 34,\n",
       " 88.0: 35,\n",
       " 66.0: 36,\n",
       " 49.0: 37,\n",
       " 78.0: 38,\n",
       " 90.0: 39,\n",
       " 57.0: 40,\n",
       " 70.0: 41,\n",
       " 53.0: 42,\n",
       " 46.0: 43,\n",
       " 35.0: 44,\n",
       " 86.0: 45,\n",
       " 55.0: 46,\n",
       " 44.0: 47,\n",
       " 50.0: 48,\n",
       " 36.0: 49,\n",
       " 60.0: 50,\n",
       " 38.0: 51,\n",
       " 41.0: 52,\n",
       " 47.0: 53,\n",
       " 91.0: 54,\n",
       " 92.0: 55,\n",
       " 52.0: 56,\n",
       " 33.0: 57,\n",
       " 30.0: 58,\n",
       " 19.0: 59,\n",
       " 93.0: 60,\n",
       " 94.0: 61,\n",
       " 42.0: 62,\n",
       " 31.0: 63,\n",
       " 34.0: 64,\n",
       " 98.0: 65,\n",
       " 20.0: 66,\n",
       " 96.0: 67,\n",
       " 97.0: 68,\n",
       " 95.0: 69,\n",
       " 39.0: 70,\n",
       " 26.0: 71,\n",
       " 29.0: 72,\n",
       " 16.0: 73,\n",
       " 24.0: 74,\n",
       " 8.0: 75,\n",
       " 32.0: 76,\n",
       " 9.0: 77,\n",
       " 21.0: 78,\n",
       " 23.0: 79,\n",
       " 25.0: 80,\n",
       " 7.0: 81,\n",
       " 28.0: 82,\n",
       " 13.0: 83,\n",
       " 10.0: 84,\n",
       " 11.0: 85,\n",
       " 22.0: 86,\n",
       " 27.0: 87,\n",
       " 18.0: 88}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enum = {k:j for j, k in enumerate(df['labels'].unique())}\n",
    "label_enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df['labels'].apply(lambda x: [1.0 if label_enum[x]==i else 0.0 for i in range(len(set(targets)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_data = Dataset.from_pandas(train)\n",
    "val_data = Dataset.from_pandas(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3207c666645946e1b5d6adcb43a0ff94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c035333eedfc4cfd9fe48fbc74e0e905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_data.map(tokenize_function, batched=True)\n",
    "val_dataset = val_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(['__index_level_0__', 'text'])\n",
    "val_dataset = val_dataset.remove_columns(['__index_level_0__', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"pt\", columns=[\"input_ids\", 'token_type_ids', 'attention_mask'], output_all_columns=True)\n",
    "val_dataset.set_format(\"pt\", columns=[\"input_ids\", 'token_type_ids', 'attention_mask'], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           num_labels=len(set(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=peft.TaskType.SEQ_CLS,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_former = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 363353 || all params: 109914034 || trainable%: 0.3305792597876992\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  no_cuda=False,\n",
    "                                  learning_rate=1e-3,\n",
    "                                  push_to_hub=False,\n",
    "                                  num_train_epochs=1,\n",
    "                                  evaluation_strategy='steps',\n",
    "                                  eval_steps=50,\n",
    "                                  logging_strategy=\"steps\",\n",
    "                                  logging_steps=50\n",
    "                                  )\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids'].unsqueeze(0)\n",
    "attention_mask = inputs['attention_mask'].unsqueeze(0)\n",
    "token_type_ids = inputs['token_type_ids'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW I STOPPED HERE! CHECK EVAL FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask, token_type_ids).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4693, -0.0622,  0.7178,  0.1627, -0.1421, -0.1235,  0.2952,  0.0544,\n",
       "          0.6805,  0.6063, -0.4417, -0.3302, -0.0539, -0.3465,  0.2902,  0.1370,\n",
       "         -0.1958,  0.0670, -0.5611,  0.1078, -0.1611, -0.8442, -0.5220,  0.2288,\n",
       "         -0.0096,  0.6315, -0.1905, -0.5507,  0.2417,  0.1591,  0.1722, -0.2233,\n",
       "         -0.3620,  0.2168, -0.6344,  0.1465, -0.3930, -0.1170,  0.4615,  0.6546,\n",
       "         -0.1103,  0.6494,  0.2672,  0.0044, -0.4229,  0.2915, -0.0084, -0.1462,\n",
       "          0.1175,  0.4064, -0.3995,  0.1832, -0.0530, -0.8782,  0.4476,  0.6353,\n",
       "         -0.2529, -0.5343,  0.4150, -0.3722, -0.1825,  0.6289, -0.3182, -0.2007,\n",
       "         -0.0403,  0.2832, -0.0419,  0.3674, -0.2599,  0.4915, -0.3517,  0.2709,\n",
       "          0.0086, -0.3790, -0.2798, -0.1293,  0.0945,  0.5888, -0.0504,  0.2047,\n",
       "          0.1439, -0.5780, -0.1910, -0.2142, -0.2117, -0.1576, -0.0979, -0.1142,\n",
       "         -0.1970]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrama30765\u001b[0m (\u001b[33mramzes\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\My_projects\\Grapix\\garpix-solution\\notebooks\\Ramzes\\wandb\\run-20240223_000709-wxefxmpe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ramzes/huggingface/runs/wxefxmpe' target=\"_blank\">dancing-orchid-13</a></strong> to <a href='https://wandb.ai/ramzes/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ramzes/huggingface' target=\"_blank\">https://wandb.ai/ramzes/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ramzes/huggingface/runs/wxefxmpe' target=\"_blank\">https://wandb.ai/ramzes/huggingface/runs/wxefxmpe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688b77b960794e56bb94a5abfbca0c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1036, 'learning_rate': 0.0009000000000000001, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac988761d2847e9b530ac4f4dda3f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: [38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38\n 38 38 38 38 36 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38],\nInput references: [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\notebooks\\Ramzes\\try_peft_bert.ipynb Ячейка 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/My_projects/Grapix/garpix-solution/notebooks/Ramzes/try_peft_bert.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1537\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m     )\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m steps_skipped) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[0;32m   1927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m-> 1929\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[0;32m   1930\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\transformers\\trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2289\u001b[0m metrics \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 2291\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[0;32m   2292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2294\u001b[0m     \u001b[39m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\transformers\\trainer.py:3095\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3092\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3094\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3095\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[0;32m   3096\u001b[0m     eval_dataloader,\n\u001b[0;32m   3097\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   3098\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3099\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3100\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   3101\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[0;32m   3102\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[0;32m   3103\u001b[0m )\n\u001b[0;32m   3105\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[0;32m   3106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\transformers\\trainer.py:3386\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3382\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(\n\u001b[0;32m   3383\u001b[0m             EvalPrediction(predictions\u001b[39m=\u001b[39mall_preds, label_ids\u001b[39m=\u001b[39mall_labels, inputs\u001b[39m=\u001b[39mall_inputs)\n\u001b[0;32m   3384\u001b[0m         )\n\u001b[0;32m   3385\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3386\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(EvalPrediction(predictions\u001b[39m=\u001b[39;49mall_preds, label_ids\u001b[39m=\u001b[39;49mall_labels))\n\u001b[0;32m   3387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3388\u001b[0m     metrics \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\notebooks\\Ramzes\\try_peft_bert.ipynb Ячейка 34\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/My_projects/Grapix/garpix-solution/notebooks/Ramzes/try_peft_bert.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m logits, labels \u001b[39m=\u001b[39m eval_pred\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/My_projects/Grapix/garpix-solution/notebooks/Ramzes/try_peft_bert.ipynb#Y116sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(logits, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/My_projects/Grapix/garpix-solution/notebooks/Ramzes/try_peft_bert.ipynb#Y116sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m metric\u001b[39m.\u001b[39;49mcompute(predictions\u001b[39m=\u001b[39;49mpredictions, references\u001b[39m=\u001b[39;49mlabels)\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\evaluate\\module.py:450\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m compute_kwargs \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m kwargs \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feature_names()}\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m--> 450\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_batch(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalize()\n\u001b[0;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_file_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\My_projects\\Grapix\\garpix-solution\\.venv\\lib\\site-packages\\evaluate\\module.py:541\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     error_msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    536\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredictions and/or references don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match the expected format.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_feature_format\u001b[39m \u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput predictions: \u001b[39m\u001b[39m{\u001b[39;00msummarize_if_long_list(predictions)\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput references: \u001b[39m\u001b[39m{\u001b[39;00msummarize_if_long_list(references)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m     )\n\u001b[1;32m--> 541\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(error_msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: [38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38\n 38 38 38 38 36 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 36 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 36 38 38 38 38 38 38 38 38 38],\nInput references: [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
